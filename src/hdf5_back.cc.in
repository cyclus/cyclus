#include "hdf5_back.h"

#include <cmath>
#include <string.h>
#include <iostream>

#include "blob.h"

namespace cyclus {

Hdf5Back::Hdf5Back(std::string path) : path_(path) {
  H5open();
  hasher_.Clear();
  if (boost::filesystem::exists(path_))
    file_ = H5Fopen(path_.c_str(), H5F_ACC_RDWR, H5P_DEFAULT);
  else
    file_ = H5Fcreate(path_.c_str(), H5F_ACC_TRUNC, H5P_DEFAULT, H5P_DEFAULT);
  opened_types_.clear();
  vldatasets_.clear();
  vldts_.clear();
  vlkeys_.clear();

  uuid_type_ = H5Tcopy(H5T_C_S1);
  H5Tset_size(uuid_type_, CYCLUS_UUID_SIZE);
  H5Tset_strpad(uuid_type_, H5T_STR_NULLPAD);
  opened_types_.insert(uuid_type_);

  hsize_t sha1_len = CYCLUS_SHA1_NINT;  // 160 bits == 32 bits / int  * 5 ints
  sha1_type_ = H5Tarray_create2(H5T_NATIVE_UINT, 1, &sha1_len);
  opened_types_.insert(sha1_type_);

  vlstr_type_ = H5Tcopy(H5T_C_S1);
  H5Tset_size(vlstr_type_, H5T_VARIABLE);
  opened_types_.insert(vlstr_type_);
  vldts_[VL_STRING] = vlstr_type_;

  blob_type_ = vlstr_type_;
  vldts_[BLOB] = blob_type_;
}

void Hdf5Back::Close() {
  // make sure we are still open
  if (closed_)
    return;

  // cleanup HDF5
  Flush();
  H5Fclose(file_);
  std::set<hid_t>::iterator t;
  for (t = opened_types_.begin(); t != opened_types_.end(); ++t)
    H5Tclose(*t);
  std::map<std::string, hid_t>::iterator vldsit;
  for (vldsit = vldatasets_.begin(); vldsit != vldatasets_.end(); ++vldsit)
    H5Dclose(vldsit->second);

  // cleanup memory
  std::map<std::string, size_t*>::iterator it;
  std::map<std::string, DbTypes*>::iterator dbtit;
  for (it = col_offsets_.begin(); it != col_offsets_.end(); ++it) {
    delete[](it->second);
  }
  for (it = col_sizes_.begin(); it != col_sizes_.end(); ++it) {
    delete[](it->second);
  }
  for (dbtit = schemas_.begin(); dbtit != schemas_.end(); ++dbtit) {
    delete[](dbtit->second);
  }

  closed_ = true;
}

Hdf5Back::~Hdf5Back() {
  if (!closed_)
    Close();
}

void Hdf5Back::Notify(DatumList data) {
  std::map<std::string, DatumList> groups;
  for (DatumList::iterator it = data.begin(); it != data.end(); ++it) {
    std::string name = (*it)->title();
    if (schema_sizes_.count(name) == 0) {
      if (H5Lexists(file_, name.c_str(), H5P_DEFAULT)) {
        LoadTableTypes(name, (*it)->vals().size(), *it);
      } else {
        // Datum* d = *it;
        // CreateTable(d);
        CreateTable(*it);
      }
    }
    groups[name].push_back(*it);
  }

  std::map<std::string, DatumList>::iterator it;
  for (it = groups.begin(); it != groups.end(); ++it) {
    WriteGroup(it->second);
  }
}

template <>
std::string Hdf5Back::VLRead<std::string, VL_STRING>(const char* rawkey) {
  using std::string;
  // key is used as offset
  Digest key;
  memcpy(key.val, rawkey, CYCLUS_SHA1_SIZE);
  const std::vector<hsize_t> idx = key.cast<hsize_t>();
  hid_t dset = VLDataset(VL_STRING, false);
  hid_t dspace = H5Dget_space(dset);
  hid_t mspace = H5Screate_simple(CYCLUS_SHA1_NINT, vlchunk_, NULL);
  herr_t status = H5Sselect_hyperslab(dspace, H5S_SELECT_SET,
                                      (const hsize_t*) &idx[0],
                                      NULL, vlchunk_, NULL);
  if (status < 0)
    throw IOError("could not select hyperslab of string value array for reading "
                  "in the database '" + path_ + "'.");
  char** buf = new char*[sizeof(char *)];
  status = H5Dread(dset, vldts_[VL_STRING], mspace, dspace, H5P_DEFAULT, buf);
  if (status < 0)
    throw IOError("failed to read in variable length string data "
                  "in database '" + path_ + "'.");
  string val;
  if (buf[0] != NULL)
    val = string(buf[0]);
  status = H5Dvlen_reclaim(vldts_[VL_STRING], mspace, H5P_DEFAULT, buf);
  if (status < 0)
    throw IOError("failed to reclaim variable length string data space in "
                  "database '" + path_ + "'.");
  delete[] buf;
  H5Sclose(mspace);
  H5Sclose(dspace);
  return val;
}

template <>
Blob Hdf5Back::VLRead<Blob, BLOB>(const char* rawkey) {
  // key is used as offset
  Digest key;
  memcpy(key.val, rawkey, CYCLUS_SHA1_SIZE);
  const std::vector<hsize_t> idx = key.cast<hsize_t>();
  hid_t dset = VLDataset(BLOB, false);
  hid_t dspace = H5Dget_space(dset);
  hid_t mspace = H5Screate_simple(CYCLUS_SHA1_NINT, vlchunk_, NULL);
  herr_t status = H5Sselect_hyperslab(dspace, H5S_SELECT_SET,
                                      (const hsize_t*) &idx[0],
                                      NULL, vlchunk_, NULL);
  if (status < 0)
    throw IOError("could not select hyperslab of Blob value array for reading "
                  "in the database '" + path_ + "'.");
  char** buf = new char*[sizeof(char *)];
  status = H5Dread(dset, vldts_[BLOB], mspace, dspace, H5P_DEFAULT, buf);
  if (status < 0)
    throw IOError("failed to read in Blob data in database '" + path_ + "'.");
  Blob val = Blob(buf[0]);
  status = H5Dvlen_reclaim(vldts_[BLOB], mspace, H5P_DEFAULT, buf);
  if (status < 0)
    throw IOError("failed to reclaim Blob data space in database "
                  "'" + path_ + "'.");
  delete[] buf;
  H5Sclose(mspace);
  H5Sclose(dspace);
  return val;
}

QueryResult Hdf5Back::Query(std::string table, std::vector<Cond>* conds) {
  using std::string;
  using std::vector;
  using std::set;
  using std::list;
  using std::pair;
  using std::map;
  if (!H5Lexists(file_, table.c_str(), H5P_DEFAULT))
    throw IOError("table '" + table + "' does not exist in '" + path_ + "'.");
  int i;
  int j;
  int jlen;
  herr_t status = 0;
  hid_t tb_set = H5Dopen2(file_, table.c_str(), H5P_DEFAULT);
  hid_t tb_space = H5Dget_space(tb_set);
  hid_t tb_plist = H5Dget_create_plist(tb_set);
  hid_t tb_type = H5Dget_type(tb_set);
  size_t tb_typesize = H5Tget_size(tb_type);
  int tb_length = H5Sget_simple_extent_npoints(tb_space);
  hsize_t tb_chunksize;
  H5Pget_chunk(tb_plist, 1, &tb_chunksize);
  unsigned int nchunks =
      (tb_length/tb_chunksize) + (tb_length%tb_chunksize == 0?0:1);

  // set up field-conditions map
  std::map<std::string, std::vector<Cond*> > field_conds =
      std::map<std::string, std::vector<Cond*> >();
  if (conds != NULL) {
    Cond* cond;
    for (i = 0; i < conds->size(); ++i) {
      cond = &((*conds)[i]);
      if (field_conds.count(cond->field) == 0)
        field_conds[cond->field] = std::vector<Cond*>();
      field_conds[cond->field].push_back(cond);
    }
  }

  // read in data
  QueryResult qr = GetTableInfo(table, tb_set, tb_type);
  int nfields = qr.fields.size();
  for (i = 0; i < nfields; ++i) {
    if (field_conds.count(qr.fields[i]) == 0) {
      field_conds[qr.fields[i]] = std::vector<Cond*>();
    }
  }
  for (unsigned int n = 0; n < nchunks; ++n) {
    // This loop is meant to be OpenMP-izable
    hid_t field_type;
    hsize_t start = n * tb_chunksize;
    hsize_t count =
        (tb_length-start) < tb_chunksize ? tb_length - start : tb_chunksize;
    char* buf = new char[tb_typesize * count];
    hid_t memspace = H5Screate_simple(1, &count, NULL);
    status = H5Sselect_hyperslab(tb_space, H5S_SELECT_SET, &start, NULL,
                                 &count, NULL);
    status = H5Dread(tb_set, tb_type, memspace, tb_space, H5P_DEFAULT, buf);
    int offset = 0;
    bool is_row_selected;
    for (i = 0; i < count; ++i) {
      offset = i * tb_typesize;
      is_row_selected = true;
      QueryRow row = QueryRow(nfields);
      for (j = 0; j < nfields; ++j) {
        switch (qr.types[j]) {
@HDF5_BACK_CC_QUERY@
          default: {
            throw IOError("querying column '" + qr.fields[j] + "' in table '" + \
                          table + "' failed due to unsupported data type.");
            break;
          }
        }
        if (!is_row_selected)
          break;
        offset += col_sizes_[table][j];
      }
      if (is_row_selected) {
        qr.rows.push_back(row);
      }
    }
    delete[] buf;
    H5Sclose(memspace);
  }

  // close and return
  H5Tclose(tb_type);
  H5Pclose(tb_plist);
  H5Sclose(tb_space);
  H5Dclose(tb_set);
  return qr;
}

QueryResult Hdf5Back::GetTableInfo(std::string title, hid_t dset, hid_t dt) {
  int i;
  char * colname;
  hsize_t ncols = H5Tget_nmembers(dt);
  std::string fieldname;
  std::string fieldtype;
  LoadTableTypes(title, dset, ncols);
  DbTypes* dbtypes = schemas_[title];

  QueryResult qr;
  for (i = 0; i < ncols; ++i) {
    colname = H5Tget_member_name(dt, i);
    fieldname = std::string(colname);
    free(colname);
    qr.fields.push_back(fieldname);
    qr.types.push_back(dbtypes[i]);
  }
  return qr;
}

void Hdf5Back::LoadTableTypes(std::string title, hsize_t ncols, Datum *d) {
  if (schemas_.count(title) > 0)
    return;
    
  hid_t dset = H5Dopen2(file_, title.c_str(), H5P_DEFAULT);
  if(dset < 0) {
    CreateTable(d);
    return;
  }
  LoadTableTypes(title, dset, ncols);
  H5Dclose(dset);
}

void Hdf5Back::LoadTableTypes(std::string title, hid_t dset, hsize_t ncols) {
  if (schemas_.count(title) > 0)
    return;

  int i;
  hid_t subt;
  hid_t t = H5Dget_type(dset);
  schema_sizes_[title] = H5Tget_size(t);
  size_t* offsets = new size_t[ncols];
  size_t* sizes = new size_t[ncols];
  for (i = 0; i < ncols; ++i) {
    offsets[i] = H5Tget_member_offset(t, i);
    subt = H5Tget_member_type(t, i);
    sizes[i] = H5Tget_size(subt);
    H5Tclose(subt);
  }
  H5Tclose(t);
  col_offsets_[title] = offsets;
  col_sizes_[title] = sizes;

  // get types from db
  int dbt[ncols];
  hid_t dbtypes_attr = H5Aopen(dset, "cyclus_dbtypes", H5P_DEFAULT);
  hid_t dbtypes_type = H5Aget_type(dbtypes_attr);
  H5Aread(dbtypes_attr, dbtypes_type, dbt);
  H5Tclose(dbtypes_type);
  H5Aclose(dbtypes_attr);

  // store types
  DbTypes* dbtypes = new DbTypes[ncols];
  for (i = 0; i < ncols; ++i)
    dbtypes[i] = static_cast<DbTypes>(dbt[i]);
  schemas_[title] = dbtypes;
}

hid_t Hdf5Back::CreateFLStrType(int n) {
  hid_t str_type = H5Tcopy(H5T_C_S1);
  H5Tset_size(str_type, n);
  H5Tset_strpad(str_type, H5T_STR_NULLPAD);
  opened_types_.insert(str_type);
  return str_type;
}

std::string Hdf5Back::Name() {
  return path_;
}

void Hdf5Back::CreateTable(Datum* d) {
  using std::set;
  using std::string;
  using std::vector;
  using std::list;
  using std::pair;
  using std::list;
  using std::map;
  Datum::Vals vals = d->vals();
  hsize_t nvals = vals.size();
  Datum::Shape shape;
  Datum::Shapes shapes = d->shapes();

  herr_t status;
  size_t dst_size = 0;
  size_t* dst_offset = new size_t[nvals];
  size_t* dst_sizes = new size_t[nvals];
  hid_t field_types[nvals];
  DbTypes* dbtypes = new DbTypes[nvals];
  const char* field_names[nvals];
  for (int i = 0; i < nvals; ++i) {
    dst_offset[i] = dst_size;
    field_names[i] = vals[i].first;
    const std::type_info& valtype = vals[i].second.type();
@HDF5_BACK_CC_CREATE@
    dst_size += dst_sizes[i];
  }

  std::string titlestr = d->title();
  const char* title = titlestr.c_str();
  int compress = 1;
  int chunk_size = 1024;
  void* fill_data = NULL;
  void* data = NULL;

  // Make the table
  status = H5TBmake_table(title, file_, title, nvals, 0, dst_size,
                          field_names, dst_offset, field_types, chunk_size,
                          fill_data, compress, data);
  if (status < 0) {
    std::stringstream ss;
    ss << "Failed to create HDF5 table:\n" \
       << "  file      " << path_ << "\n" \
       << "  table     " << title << "\n" \
       << "  chunksize " << chunk_size << "\n" \
       << "  rowsize   " << dst_size << "\n";
    for (int i = 0; i < nvals; ++i) {
      ss << "    #" << i << " " << field_names[i] << "\n" \
         << "      dbtype: " << dbtypes[i] << "\n" \
         << "      h5type: " << field_types[i] << "\n" \
         << "      size:   " << dst_sizes[i] << "\n" \
         << "      offset: " << dst_offset[i] << "\n";
    }
    throw IOError(ss.str());
  }

  // add dbtypes attribute
  hid_t tb_set = H5Dopen2(file_, title, H5P_DEFAULT);
  hid_t attr_space = H5Screate_simple(1, &nvals, &nvals);
  hid_t dbtypes_attr = H5Acreate2(tb_set, "cyclus_dbtypes", H5T_NATIVE_INT,
                                  attr_space, H5P_DEFAULT, H5P_DEFAULT);
  H5Awrite(dbtypes_attr, H5T_NATIVE_INT, dbtypes);
  H5Aclose(dbtypes_attr);
  H5Sclose(attr_space);
  for(int i = 0; i < nvals; ++i) {
    shape = shapes[i];
    hsize_t nshape = shape.size();
    // if no shape is present, we set a primitive size of 1.
    if(shape.size() == 0) {
      nshape = 1;
    }
    hid_t shape_space = H5Screate_simple(1, &nshape, &nshape);
    std::vector<int> shape_vector;
    for(int j = 0; j < shape.size(); ++j) {
      shape_vector.push_back(shape[j]);
    }
    // default shape value is -1, which denotes primitives 
    if(shape.size() == 0) {
      shape_vector.push_back(-1);
    }
    std::stringstream col_name;
    col_name << "shape" << i;
    hid_t shape_attr = H5Acreate2(tb_set, col_name.str().c_str(), H5T_NATIVE_INT, 
                                  shape_space, H5P_DEFAULT, H5P_DEFAULT);
    H5Awrite(shape_attr, H5T_NATIVE_INT, &shape_vector[0]);
    H5Aclose(shape_attr);
    H5Sclose(shape_space);
  }
  H5Dclose(tb_set);

  // record everything for later
  col_offsets_[d->title()] = dst_offset;
  schema_sizes_[d->title()] = dst_size;
  col_sizes_[d->title()] = dst_sizes;
  schemas_[d->title()] = dbtypes;
}

std::map<std::string, DbTypes> Hdf5Back::ColumnTypes(std::string table) {
  using std::string;
  int i;
  char* colname;
  hid_t dset = H5Dopen2(file_, table.c_str(), H5P_DEFAULT);
  hid_t dt = H5Dget_type(dset);
  hsize_t ncols = H5Tget_nmembers(dt);
  string fieldname;
  string fieldtype;
  LoadTableTypes(table, dset, ncols);
  DbTypes* dbtypes = schemas_[table];

  // create return value
  std::map<string, DbTypes> rtn;
  for (i = 0; i < ncols; ++i) {
    colname = H5Tget_member_name(dt, i);
    fieldname = string(colname);
    free(colname);
    rtn[fieldname] = dbtypes[i];
  }

  // close and return
  H5Tclose(dt);
  H5Dclose(dset);
  return rtn;
}

std::list<ColumnInfo> Hdf5Back::Schema(std::string table) {
  std::list<ColumnInfo> schema;
  hid_t tb_set = H5Dopen2(file_, table.c_str(), H5P_DEFAULT);
  hid_t tb_type = H5Dget_type(tb_set);
  int i;
  hsize_t ncols = H5Tget_nmembers(tb_type);
  LoadTableTypes(table, tb_set, ncols);
  DbTypes* dbtypes = schemas_[table];
  char * colname;
    
  for (i = 0; i < ncols; ++i) {
    colname = H5Tget_member_name(tb_type, i);
    std::stringstream attr_name;
    attr_name << "shape" << i;
    hid_t attr_id = H5Aopen_by_name(tb_set, ".", attr_name.str().c_str(), H5P_DEFAULT, H5P_DEFAULT);
    hid_t attr_space = H5Aget_space(attr_id);
    int ndims = H5Sget_simple_extent_npoints(attr_space);
    std::vector<int> shape(ndims);
    H5Aread(attr_id, H5T_NATIVE_INT, &shape[0]);
    std::string colname_str = std::string(colname);
    ColumnInfo info = ColumnInfo(table, colname_str, i, dbtypes[i], shape);
    schema.push_back(info);
    free(colname);
    H5Sclose(attr_space);
    H5Aclose(attr_id);
  }
  H5Tclose(tb_type);
  H5Dclose(tb_set);
  
  return schema;
}

std::set<std::string> Hdf5Back::Tables() {
  using std::set;
  using std::string;
  set<string> rtn;
  hsize_t i;
  hsize_t n;
  ssize_t namelen;
  char name[500];
  H5G_info_t root_info;
  hid_t root = H5Gopen(file_, "/", H5P_DEFAULT);
  herr_t err = H5Gget_info(root, &root_info);
  for (i = 0; i < root_info.nlinks; ++i) {
    namelen = H5Lget_name_by_idx(root, ".", H5_INDEX_NAME, H5_ITER_NATIVE, i,
                                 NULL, 0, H5P_DEFAULT);
    H5Lget_name_by_idx(root, ".", H5_INDEX_NAME, H5_ITER_NATIVE, i,
                       name, namelen+1, H5P_DEFAULT);
    std::string str_name = std::string(name, namelen);
    if (str_name.size() >= 4 && str_name.substr(str_name.size()-4) != "Keys" && str_name.substr(str_name.size()-4) != "Vals") {
        rtn.insert(str_name);
    } else if (str_name.size() < 4) {
        rtn.insert(str_name);
    }
  }
  H5Gclose(root);
  return rtn;
}

void Hdf5Back::WriteGroup(DatumList& group) {
  std::string title = group.front()->title();
  const char * c_title = title.c_str();

  size_t* offsets = col_offsets_[title];
  size_t* sizes = col_sizes_[title];
  size_t rowsize = schema_sizes_[title];

  char* buf = new char[group.size() * rowsize];
  FillBuf(title, buf, group, sizes, rowsize);

  // We cannot do the simple thing (append_records) here because of a bug in
  // H5TB where it stupidly tries to reconstruct the datatype in memory from
  // what it read in on disk. This works in most cases but failed where the table
  // had a column which is an array of a compound datatype of non-homogenous
  // fields (eg MAP_INT_DOUBLE). The fix here just uses the datatype present on
  // disk - which is what we wanted anyway!
  //herr_t status = H5TBappend_records(file_, title.c_str(), group.size(), rowsize,
  //                            offsets, sizes, buf);
  herr_t status;
  hid_t dset = H5Dopen2(file_, title.c_str(), H5P_DEFAULT);
  hid_t dtype = H5Dget_type(dset);
  hsize_t nrecords_add = group.size();
  hsize_t nrecords_orig;
  hsize_t nfields;
  hsize_t dims[1];
  hsize_t offset[1];
  hsize_t count[1];
  H5TBget_table_info(file_, c_title, &nfields, &nrecords_orig);
  dims[0] = nrecords_add + nrecords_orig;
  offset[0] = nrecords_orig;
  count[0] = nrecords_add;

  status = H5Dset_extent(dset, dims);
  hid_t dspace = H5Dget_space(dset);
  hid_t memspace = H5Screate_simple(1, count, NULL);
  status = H5Sselect_hyperslab(dspace, H5S_SELECT_SET, offset, NULL, count, NULL);
  status = H5Dwrite(dset, dtype, memspace, dspace, H5P_DEFAULT, buf);

  if (status < 0) {
    std::stringstream ss;
    ss << "Failed to write to the HDF5 table:\n" \
       << "  file      " << path_ << "\n" \
       << "  table     " << title << "\n" \
       << "  num. rows " << group.size() << "\n"
       << "  rowsize   " << rowsize << "\n";
    for (int i = 0; i < group.front()->vals().size(); ++i) {
      ss << "    # Column " << i << "\n" \
         << "      dbtype: " << schemas_[title][i] << "\n" \
         << "      size:   " << sizes[i] << "\n" \
         << "      offset: " << offsets[i] << "\n";
    }
    throw IOError(ss.str());
  }

  H5Sclose(memspace);
  H5Sclose(dspace);
  H5Tclose(dtype);
  H5Dclose(dset);
  delete[] buf;
}

template <typename T, DbTypes U>
Digest Hdf5Back::VLWrite(const T& x) {
  hasher_.Clear();
  hasher_.Update(x);
  Digest key = hasher_.digest();
  hid_t keysds = VLDataset(U, true);
  hid_t valsds = VLDataset(U, false);
  if (vlkeys_[U].count(key) == 1)
    return key;
  hvl_t buf = VLValToBuf(x);
  AppendVLKey(keysds, U, key);
  InsertVLVal(valsds, U, key, buf);
  return key;
}

template <>
Digest Hdf5Back::VLWrite<std::string, VL_STRING>(const std::string& x) {
  hasher_.Clear();
  hasher_.Update(x);
  Digest key = hasher_.digest();
  hid_t keysds = VLDataset(VL_STRING, true);
  hid_t valsds = VLDataset(VL_STRING, false);
  if (vlkeys_[VL_STRING].count(key) == 1)
    return key;
  AppendVLKey(keysds, VL_STRING, key);
  InsertVLVal(valsds, VL_STRING, key, x);
  return key;
}

template <>
Digest Hdf5Back::VLWrite<Blob, BLOB>(const Blob& x) {
  hasher_.Clear();
  hasher_.Update(x);
  Digest key = hasher_.digest();
  hid_t keysds = VLDataset(BLOB, true);
  hid_t valsds = VLDataset(BLOB, false);
  if (vlkeys_[BLOB].count(key) == 1)
    return key;
  AppendVLKey(keysds, BLOB, key);
  InsertVLVal(valsds, BLOB, key, x.str());
  return key;
}

@HDF5_BACK_CC_WRITE@

void Hdf5Back::FillBuf(std::string title, char* buf, DatumList& group,
                       size_t* sizes, size_t rowsize) {
  using std::min;
  using std::string;
  using std::vector;
  using std::set;
  using std::list;
  using std::pair;
  using std::map;
  Datum::Vals vals;
  Datum::Shape shape;
  Datum::Shapes shapes;
  Datum::Vals header = group.front()->vals();
  int ncols = header.size();
  DbTypes* dbtypes = schemas_[title];

  size_t offset = 0;
  const void* val;
  size_t fieldlen;
  size_t valuelen;
  DatumList::iterator it;
  for (it = group.begin(); it != group.end(); ++it) {
    vals = (*it)->vals();
    shapes = (*it)->shapes();
    for (int col = 0; col < ncols; ++col) {
      const boost::spirit::hold_any* a = &(vals[col].second);
      switch (dbtypes[col]) {
@HDF5_BACK_CC_FILL_BUF@
        default: {
          throw ValueError("attempted to retrieve unsupported HDF5 backend type");
        }
      }
      offset += sizes[col];
    }
  }
}

template <typename T, DbTypes U>
T Hdf5Back::VLRead(const char* rawkey) {
  // key is used as offset
  Digest key;
  memcpy(key.val, rawkey, CYCLUS_SHA1_SIZE);
  const std::vector<hsize_t> idx = key.cast<hsize_t>();
  hid_t dset = VLDataset(U, false);
  hid_t dspace = H5Dget_space(dset);
  hid_t mspace = H5Screate_simple(CYCLUS_SHA1_NINT, vlchunk_, NULL);
  herr_t status = H5Sselect_hyperslab(dspace, H5S_SELECT_SET, (const hsize_t*) &idx[0],
                                      NULL, vlchunk_, NULL);
  if (status < 0)
    throw IOError("could not select hyperslab of value array for reading "
                  "in the database '" + path_ + "'.");
  hvl_t buf;
  status = H5Dread(dset, vldts_[U], mspace, dspace, H5P_DEFAULT, &buf);
  if (status < 0) {
    std::stringstream ss;
    ss << U;
    throw IOError("failed to read in variable length data "
                  "in the database '" + path_ + "' (type id " + ss.str() +
                  ").");
  }
  T val = VLBufToVal<T>(buf);
  status = H5Dvlen_reclaim(vldts_[U], mspace, H5P_DEFAULT, &buf);
  if (status < 0)
    throw IOError("failed to reclaim variable length data space "
                  "in the database '" + path_ + "'.");
  H5Sclose(mspace);
  H5Sclose(dspace);
  return val;
}


hid_t Hdf5Back::VLDataset(DbTypes dbtype, bool forkeys) {
  std::string name;
  switch (dbtype) {
@HDF5_BACK_CC_VL_DATASET@
    default: {
      throw IOError("could not determine variable length dataset name.");
      break;
    }
  }
  name += forkeys ? "Keys" : "Vals";

  // already opened
  if (vldatasets_.count(name) > 0)
    return vldatasets_[name];

  // already in db
  hid_t dt;
  hid_t dset;
  hid_t dspace;
  herr_t status;
  if (H5Lexists(file_, name.c_str(), H5P_DEFAULT)) {
    dset = H5Dopen2(file_, name.c_str(), H5P_DEFAULT);
    if (forkeys) {
      // read in existing keys to vlkeys_
      dspace = H5Dget_space(dset);
      unsigned int nkeys = H5Sget_simple_extent_npoints(dspace);
      char* buf = new char[CYCLUS_SHA1_SIZE * nkeys];
      status = H5Dread(dset, sha1_type_, H5S_ALL, H5S_ALL, H5P_DEFAULT, buf);
      if (status < 0)
        throw IOError("failed to read in keys for " + name);
      for (int n = 0; n < nkeys; ++n) {
        Digest d = Digest();
        memcpy(d.val, buf + (n * CYCLUS_SHA1_SIZE), CYCLUS_SHA1_SIZE);
        vlkeys_[dbtype].insert(d);
      }
      H5Sclose(dspace);
      delete[] buf;
    } else {
      if (vldts_.count(dbtype) == 0) {
        dt = H5Dget_type(dset);
        if (dt < 0)
          throw IOError("failed to read in HDF5 datatype for " + name);
        vldts_[dbtype] = dt;
      }
    }
    vldatasets_[name] = dset;
    return dset;
  }

  // doesn't exist at all
  hid_t prop;
  if (forkeys) {
    hsize_t dims[1] = {0};
    hsize_t maxdims[1] = {H5S_UNLIMITED};
    hsize_t chunkdims[1] = {512};  // this is a 10 kb chunksize
    dt = sha1_type_;
    dspace = H5Screate_simple(1, dims, maxdims);
    prop = H5Pcreate(H5P_DATASET_CREATE);
    status = H5Pset_chunk(prop, 1, chunkdims);
    if (status < 0)
      throw IOError("could not create HDF5 array " + name);
  } else {
    hsize_t dims[CYCLUS_SHA1_NINT] = {UINT_MAX, UINT_MAX, UINT_MAX, UINT_MAX, UINT_MAX};
    hsize_t chunkdims[CYCLUS_SHA1_NINT] = {1, 1, 1, 1, 1};  // this is a single element
    dt = vldts_[dbtype];
    dspace = H5Screate_simple(CYCLUS_SHA1_NINT, dims, dims);
    prop = H5Pcreate(H5P_DATASET_CREATE);
    status = H5Pset_chunk(prop, CYCLUS_SHA1_NINT, chunkdims);
    if (status < 0)
      throw IOError("could not create HDF5 array " + name);
  }
  dset = H5Dcreate2(file_, name.c_str(), dt, dspace, H5P_DEFAULT, prop, H5P_DEFAULT);
  vldatasets_[name] = dset;
  return dset;
}

void Hdf5Back::AppendVLKey(hid_t dset, DbTypes dbtype, const Digest& key) {
  hid_t dspace = H5Dget_space(dset);
  hsize_t origlen = H5Sget_simple_extent_npoints(dspace);
  hsize_t newlen[1] = {origlen + 1};
  hsize_t offset[1] = {origlen};
  hsize_t extent[1] = {1};
  hid_t mspace = H5Screate_simple(1, extent, NULL);
  herr_t status = H5Dextend(dset, newlen);
  if (status < 0)
    throw IOError("could not resize key array in the database '" + path_ + "'.");
  dspace = H5Dget_space(dset);
  status = H5Sselect_hyperslab(dspace, H5S_SELECT_SET, offset, NULL, extent, NULL);
  if (status < 0)
    throw IOError("could not select hyperslab of key array "
                  "in the database '" + path_ + "'.");
  status = H5Dwrite(dset, sha1_type_, mspace, dspace, H5P_DEFAULT, key.val);
  if (status < 0)
    throw IOError("could not write digest to key array "
                  "in the database '" + path_ + "'.");
  H5Sclose(mspace);
  H5Sclose(dspace);
  vlkeys_[dbtype].insert(key);
}

void Hdf5Back::InsertVLVal(hid_t dset, DbTypes dbtype, const Digest& key,
                           const std::string& val) {
  hid_t dspace = H5Dget_space(dset);
  hsize_t extent[CYCLUS_SHA1_NINT] = {1, 1, 1, 1, 1};
  hid_t mspace = H5Screate_simple(CYCLUS_SHA1_NINT, extent, NULL);
  const std::vector<hsize_t> idx = key.cast<hsize_t>();
  herr_t status = H5Sselect_hyperslab(dspace, H5S_SELECT_SET, (const hsize_t*) &idx[0],
                                      NULL, extent, NULL);
  if (status < 0)
    throw IOError("could not select hyperslab of value array "
                  "in the database '" + path_ + "'.");
  const char* buf[1] = {val.c_str()};
  status = H5Dwrite(dset, vldts_[dbtype], mspace, dspace, H5P_DEFAULT, buf);
  if (status < 0)
    throw IOError("could not write string to value array "
                  "in the database '" + path_ + "'.");
  H5Sclose(mspace);
  H5Sclose(dspace);
}

void Hdf5Back::InsertVLVal(hid_t dset, DbTypes dbtype, const Digest& key,
                           hvl_t buf) {
  hid_t dspace = H5Dget_space(dset);
  hsize_t extent[CYCLUS_SHA1_NINT] = {1, 1, 1, 1, 1};
  hid_t mspace = H5Screate_simple(CYCLUS_SHA1_NINT, extent, NULL);
  const std::vector<hsize_t> idx = key.cast<hsize_t>();
  herr_t status = H5Sselect_hyperslab(dspace, H5S_SELECT_SET, (const hsize_t*) &idx[0],
                                      NULL, extent, NULL);
  if (status < 0)
    throw IOError("could not select hyperslab of value array "
                  "in the database '" + path_ + "'.");
  status = H5Dwrite(dset, vldts_[dbtype], mspace, dspace, H5P_DEFAULT, &buf);
  if (status < 0)
    throw IOError("could not write variable length data to value array "
                  "in the database '" + path_ + "'.");
  status = H5Dvlen_reclaim(vldts_[dbtype], mspace, H5P_DEFAULT, &buf);
  if (status < 0)
    throw IOError("could not free variable length buffer "
                  "in the database '" + path_ + "'.");
  H5Sclose(mspace);
  H5Sclose(dspace);
}

@HDF5_BACK_CC_VAL_TO_BUF@

@HDF5_BACK_CC_BUF_TO_VAL@

}  // namespace cyclus
